{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network implementation for finding defects in semiconductor manufacturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the imports\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Data generation with random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\"\"\" 3 different class of data\n",
    "    1) Spot : p(x, y) = exp(r^2 / 2 * sigma^2), r^2 = (x - xc)^2 + (y - yc)^2, sigma => to vary width of spot\n",
    "    2) Ring : p(x, y) = 1 - exp(r^2 / 2 * sigma^2), r^2 = (x - xc)^2 + (y - yc)^2\n",
    "    3) Repititive (Horizontal)\n",
    "\"\"\"\n",
    "\n",
    "def spot_prob(x, y, sigma, xc, yc) :\n",
    "    rsquare = (x - xc) ** 2 + (y - yc) ** 2\n",
    "    return min(1, (np.random.random() * 0.75 + np.exp(-rsquare / 2 * (sigma ** 2))))\n",
    "\n",
    "def ring_prob(x, y, sigma, xc, yc) :\n",
    "    rsquare = (x - xc) ** 2 + (y - yc) ** 2\n",
    "    return min(1, (np.random.random() * 0.75 + 1 - np.exp(-rsquare / 2 * (sigma ** 2))))\n",
    "\n",
    "def repititive_horizontal_prob(x, y, T, phi) :\n",
    "    return min(1, (np.random.random() * 0.75 + (1 + np.sin(2 * np.pi * x / T + phi)) / 2))\n",
    "\n",
    "def plot_grayscale(image) :\n",
    "    plt.imshow(image, cmap = 'gray', vmin = 0, vmax = 1)\n",
    "    plt.show()\n",
    "\n",
    "def spot_gen(R, C, sigma, xc, yc) :\n",
    "    # generate a spot\n",
    "    spot = np.zeros((R, C))\n",
    "    for i in range(R) :\n",
    "        for j in range(C) :\n",
    "            spot[i][j] = 1 - spot_prob(i, j, sigma, xc, yc)\n",
    "            spot[i][j] = 1 if spot[i][j] > 0.5 else 0\n",
    "    return spot\n",
    "\n",
    "spot = spot_gen(50, 50, 0.3, 20, 20)\n",
    "plot_grayscale(spot)\n",
    "\n",
    "def ring_gen(R, C, sigma, xc, yc) :\n",
    "    ring = np.zeros((R, C))\n",
    "    for i in range(R) :\n",
    "        for j in range(C) :\n",
    "            ring[i][j] = 1 - ring_prob(i, j, sigma, xc, yc)\n",
    "            ring[i][j] = 1 if ring[i][j] > 0.5 else 0\n",
    "    return ring\n",
    "\n",
    "ring = ring_gen(50, 50, 0.05, 20.5, 20.5)\n",
    "plot_grayscale(ring)\n",
    "\n",
    "def repititive_horizontal_gen(R, C, T, phi) :\n",
    "    rh = np.zeros((R, C))\n",
    "    for i in range(R) :\n",
    "        for j in range(C) :\n",
    "            rh[i][j] = 1 - repititive_horizontal_prob(i, j, T, phi)\n",
    "            rh[i][j] = 1 if rh[i][j] > 0.5 else 0\n",
    "    return rh\n",
    "\n",
    "rh = repititive_horizontal_gen(50, 50, 5, np.pi / 4)\n",
    "plot_grayscale(rh)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data():\n",
    "#     # open dataset load the data and return\n",
    "#     f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "#     training_data, validation_data, test_data = pickle.load(f, encoding = 'latin1')\n",
    "#     f.close()\n",
    "#     return (training_data, validation_data, test_data)\n",
    "\n",
    "# def load_data_wrapper():\n",
    "#     # modify the dataset according to the need\n",
    "#     tr_d, va_d, te_d = load_data()\n",
    "#     training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n",
    "#     training_results = [vectorized_result(y) for y in tr_d[1]]\n",
    "#     training_data = list(zip(training_inputs, training_results))\n",
    "#     validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]\n",
    "#     validation_data = list(zip(validation_inputs, va_d[1]))\n",
    "#     test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]\n",
    "#     test_data = list(zip(test_inputs, te_d[1]))\n",
    "#     return (training_data, validation_data, test_data)\n",
    "\n",
    "# def vectorized_result(j):\n",
    "#     e = np.zeros((10, 1))\n",
    "#     e[j] = 1.0\n",
    "#     return e\n",
    "\n",
    "# Generate dataset (training_data, test_data)\n",
    "no_of_training_data = 5000\n",
    "no_of_test_data = 1000\n",
    "\n",
    "training_data = []\n",
    "test_data = []\n",
    "R = 50\n",
    "C = 50\n",
    "\n",
    "for it in range(no_of_training_data + no_of_test_data) :\n",
    "    index = np.random.randint(0, 3)\n",
    "#     print(index)\n",
    "    if(index == 0) :\n",
    "        xc = np.random.randint(R // 4, 3 * R // 4)\n",
    "        yc = np.random.randint(C // 4, 3 * C // 4)\n",
    "        sigma = np.random.random() * 0.75 + 0.1 # optimal range of sigma -> [0.1, 0.5)\n",
    "        spot = spot_gen(R, C, sigma, xc, yc)\n",
    "#         plot_grayscale(spot)\n",
    "        spot_input = np.reshape(spot, (R * C, 1))\n",
    "        spot_output = np.zeros((3, 1))\n",
    "        spot_output[index] = 1\n",
    "        if(it < no_of_training_data) :\n",
    "            training_data.append((spot_input, spot_output))\n",
    "        else :\n",
    "            test_data.append((spot_input, index))\n",
    "    elif (index == 1) :\n",
    "        xc = np.random.randint(R // 4, 3 * R // 4)\n",
    "        yc = np.random.randint(C // 4, 3 * C // 4)\n",
    "        sigma = np.random.random() * 0.5 # optimal range of sigma -> [0.03, 0.2)\n",
    "        ring = ring_gen(R, C, sigma, xc, yc)\n",
    "#         plot_grayscale(ring)\n",
    "        ring_input = np.reshape(ring, (R * C, 1))\n",
    "        ring_output = np.zeros((3, 1))\n",
    "        ring_output[index] = 1\n",
    "        if(it < no_of_training_data) :\n",
    "            training_data.append((ring_input, ring_output))\n",
    "        else :\n",
    "            test_data.append((ring_input, index))\n",
    "    else :\n",
    "        assert(index == 2)\n",
    "        # pick T anything from 3 to 15\n",
    "        T = 25 * np.random.random() + 3\n",
    "        phi = np.pi / 2 * np.random.random()\n",
    "        rh = repititive_horizontal_gen(R, C, T, phi)\n",
    "#         plot_grayscale(rh)\n",
    "        rh_input = np.reshape(rh, (R * C, 1))\n",
    "        rh_output = np.zeros((3, 1))\n",
    "        rh_output[index] = 1\n",
    "        if(it < no_of_training_data) :\n",
    "            training_data.append((rh_input, rh_output))\n",
    "        else :\n",
    "            test_data.append((rh_input, index))\n",
    "            \n",
    "# check the final sizes of traning_data and test_data\n",
    "assert(len(training_data) == no_of_training_data)\n",
    "assert(len(test_data) == no_of_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A module to implement the stochastic gradient descent learning\n",
    "algorithm for a feedforward neural network.  Gradients are calculated\n",
    "using backpropagation. \n",
    "\"\"\"\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.\"\"\"\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            test_data=None):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "        if test_data: n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                print (\"Epoch {0}: {1} / {2}\".format(\n",
    "                    j, self.evaluate(test_data), n_test))\n",
    "            else:\n",
    "                print (\"Epoch {0} complete\".format(j))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "        is the learning rate.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book.  Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on.  It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return (output_activations-y)\n",
    "\n",
    "#### Miscellaneous functions\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 918 / 1000\n",
      "Epoch 1: 940 / 1000\n",
      "Epoch 2: 943 / 1000\n",
      "Epoch 3: 945 / 1000\n",
      "Epoch 4: 947 / 1000\n",
      "Epoch 5: 948 / 1000\n",
      "Epoch 6: 950 / 1000\n",
      "Epoch 7: 957 / 1000\n",
      "Epoch 8: 956 / 1000\n",
      "Epoch 9: 958 / 1000\n",
      "Epoch 10: 960 / 1000\n",
      "Epoch 11: 955 / 1000\n",
      "Epoch 12: 960 / 1000\n",
      "Epoch 13: 961 / 1000\n",
      "Epoch 14: 961 / 1000\n",
      "Epoch 15: 962 / 1000\n",
      "Epoch 16: 960 / 1000\n",
      "Epoch 17: 964 / 1000\n",
      "Epoch 18: 963 / 1000\n",
      "Epoch 19: 962 / 1000\n"
     ]
    }
   ],
   "source": [
    "# training_data, validation_data, test_data = load_data_wrapper()\n",
    "\n",
    "net = Network([R * C, 30, 3])\n",
    "net.SGD(training_data, 20, 10, 2, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
